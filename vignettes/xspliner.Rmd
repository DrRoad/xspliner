---
title: "xspliner package - basic theory and usage"
author: "Krystian Igras"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  collapse = TRUE,
  comment = "#>"
)
library(randomForest)
library(pdp)
library(xspliner)
```

## Motivation

In regression or classification problem, the main issue is choosing the model that should meet our requirements as much as possible. On the one hand, we want the chosen solution to have the best statistical properties such as accuracy, SSE or R Squared - on the other hand, we focus on the interpretability of the model.

In the first case, black box models, such as randomForest or XGBoost, perform better than others, while the second case is dominated by linear models. The xspliner package aims to combine both methods: use the knowledge gathered from black box models in order to build an interpretable linear one.

## General idea

Below graphics show general idea used in xspliner model
*(todo)*

### Black box variable response

When black box model is already built, you may want to check how each predictor variable affects the final response.
This is quite easy when you use a linear model or have low dimensional data (up to 2, 3 dimensions). 
One of ideas for testing the predictor impact in more complicated model is to check an average model response of the selected variable.

One of such approaches called Partial Dependence Plots is implemented in the [pdp](https://github.com/bgreenwell/pdp) package (Brandon M. Greenwell (2017). Pdp: The R Journal, 9 (1), 421-436.), or the [ALEPlot](https://CRAN.R-project.org/package=ALEPlot) package (Dan Apley (2017). ALEPlot: Accumulated Local Effects Plots and Partial Dependence Plots.) using Accumulated Local Effects Plots.

In each case, we get a single variable function, which should explain the impact of the predictor on the response variable.

The following pictures show the `ptration` impact on `cmedv` in some randomForest model based on Boston Housing Data. Below curves are obtained by the approach of the pdp and ale methods.

```{r include = FALSE, message = FALSE}
data(boston)
set.seed(123)

# build random forest model:
boston.rf <- randomForest(cmedv ~ lstat + ptratio + age, data = boston)

# build xspline model with specified response method and approximation options
model_pdp <- xspline(
  cmedv ~
    xs(lstat, transition = list(k = 6), effect = list(type = "pdp", grid.resolution = 60)) +
    xs(ptratio, transition = list(k = 4), effect = list(type = "pdp", grid.resolution = 40)) +
    age,
  model = boston.rf
)

model_ale <- xspline(
  cmedv ~
    xs(lstat, transition = list(k = 6), effect = list(type = "ale", K = 60)) +
    xs(ptratio, transition = list(k = 4), effect = list(type = "ale", K = 40)) +
    age,
  model = boston.rf
)
```

```{r fig.width=2, fig.height=2, echo = FALSE, fig.show='hold'}
plot(model_pdp, "ptratio", plot_approx = FALSE)
plot(model_ale, "ptratio", plot_approx = FALSE)
```

As we can see, above functions are irregular, making it difficult to interpret explained effect.

If above functions had linear character, one would be tempted to approximate them with linear function. As a result one could easily interpret how it affects the variable explained in the black box model. 
What if the function is irregular, as above?

### Splines

Due to the large errors that occurs with approximation of functions with polynomials, the approach using spline approximation is most common solution. Splines (functions that piecewise polynomials) have good approximating properties, in addition their form is overt so we can thus interpret the resulting function.

The following graphics show spline approximations of pdp and ale curves:

```{r fig.width=2, fig.height=2, echo = FALSE, fig.show='hold'}
plot(model_pdp, "ptratio")
plot(model_ale, "ptratio")
```

### Linear models based on response function and splines

The general idea of how to use the response function and splines to build an interpretable model is as follows.

- For each variable used in the black box model, create a response function based on one of the known methods, let's mark it $f_{x}$
- Approximate $f_{x}$ using spline - the result is $\widetilde{f}_{x}$
- Build linear model, in which each predictior $x_{i}$ is transformed with approximated response function: $\widetilde{f}_{x_{i}}(x_{i})$

Shortly, using black box formula
$$y \sim x_{1} + \cdots + x_{n}$$
we use
$$y \sim \widetilde{f}_{x_{1}}(x_{1}) + \cdots + \widetilde{f}_{x_{n}}(x_{n})$$
in linear one.

The resulting model uses part of the information that was extracted while building black box model.

## How to do it with xspliner?

### Defining formula

This sections shows, how to build formula interpretable by xspliner package using Boston Housing Data from `pdp` package.

Read the data
```{r}
data(boston)
str(boston)
```

We're going to prepare formula 
```
cmedv ~ rm + lstat + nox
```

Specify which variables should be transformed.
In this example we will transform `nox` variable.

To indicate transformation use `xs(nos)` symbol.

So we have:
```
cmedv ~ rm + lstat + xs(nox)
```

As the algoritm goes threw creating response function and its approximation we need to specify desirable parameters.

#### Specifying which method should we use to build response function
```
effect = list(
  type = <method_type> # "pdp" or "ale",
  ... # named list - other parameters passed for chosen method
)
```

Possible parameters that can be passed into `...` find in

- `pdp::partial` in case of `type = "pdp"`
- `ALEPlot::ALEPlot` in case of `type = "ale"`

#### Specifying spline approximation parameters
Response function is approximated with `mgcv::gam` package and `mgcv::s` smoothing function.

`xspliner` allows using all smoothing methods provided by `mgcv::s`.
You can pass corresponding parameters in
```
transition = <mgcv::s parameters> # named list
```
**Remark**
One of special parameters passed for `transition` is `increasing`. 
When the parameter occurs then:

- for `TRUE` value, approximation will be increasing
- for `FALSE` value, approximation will be decreasing
<br>

Let's assume we want to build response function basing on "pdp" package.
Response function is presented as data.frame with two columns (in our case):

- `nox` - $n$ evenly spaced points across range of `nox` variable. Specified by `grid.resolution` parameter (51 by default)
- `yhat` - response function values on points specified in the first column

As we want to store 100 values for response function data, we specify in formula:
```
cmedv ~ rm + lstat + xs(nox, effect = list(type = "pdp", grid.resolution = 100))
```

We also want to approximate response function with cubic splines and basis dimension equal to 10.
As we can see in `mgcv::s` documentation, we need to set: `k = 10` and `bs = "cr"`.

So we get the final formula:
```
cmedv ~ rm + lstat + xs(nox, 
  effect = list(type = "pdp", grid.resolution = 100),
  transition = list(k = 10, bs = "cr"))
```

### Building the model

Having the formula defined, we almost have all the required data provided.
The only one left, that the approach requires is the black box model that is the basis of our resulting model.

Let's define `randomForest` for this purpose.

```{r results = FALSE}
set.seed(123)
boston_rf <- randomForest(cmedv ~ rm + lstat + nox, data = boston) 
```

As we already have the black box provided, we can use `xspline` function to build the desired model.

```{r results = FALSE}
xp_model <- xspline(
  cmedv ~ rm + lstat +
    xs(nox, 
       effect = list(type = "pdp", grid.resolution = 100), 
       transition = list(k = 10, bs = "cr")),
  model = boston_rf
)
```

Lets check the model summary:
```{r}
summary(xp_model)
```

As you can see in the summary, the final formula is simplified version of input one.
All the information about the response functions are stored in `xp_model` environment.

### Plotting the result
*(in progress)*

You may plot simple graphics for resulting model with `xp_plot` function.

```{r fig.width=3, fig.height=3, fig.show='hold'}
plot(xp_model, "nox", data = boston, plot_data = TRUE)
plot(xp_model, "nox")
```

### Is spline transformation always better?

*For qualitative variables only*

When the response function has linear form, approximating it with splines may make the result worse.
`xspline` function offers automatical check if spline approximation is better than linear one, and use it in final model.

You may find two parameters responsible for that:
- `alter` - The list of 'numeric' and 'factor'. When `alter$numeric == 'auto'`, automatically choose whther variable should be transformed with splines
- `compare_stat` - function of `lm` class object. Defines statistic that should be used in decision between spline model and linear one. The function should have attribute `higher`. When the attribute has `"better"` value then the model with higher statistic value is chosen.

You can see the feature in above example:
```{r message = FALSE}
set.seed(123)
boston_rf <- randomForest(cmedv ~ lstat + ptratio + age, data = boston) 
model_pdp_auto <- xspline(
  cmedv ~
    xs(lstat, transition = list(k = 6), effect = list(type = "pdp", grid.resolution = 60)) +
    xs(ptratio, transition = list(k = 4), effect = list(type = "pdp", grid.resolution = 40)) +
    age,
  model = boston_rf,
  xs_opts = list(transition = list(alter = "auto"))
)

# r_squared statistic is used by default

summary(model_pdp_auto)
```

Linear approximation was better for `ptratio` response function.

## Further work
See [github issues](https://github.com/krystian8207/xspliner/issues) 
